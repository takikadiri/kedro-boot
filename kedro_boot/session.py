"""This module implements Kedro boot session responsible for kedro boot app lifecycle."""

import logging
import uuid
from typing import Any, Optional, Set

from kedro.config import OmegaConfigLoader
from kedro.io import DataCatalog
from kedro.runner import SequentialRunner
from pluggy import PluginManager

from kedro_boot.catalog import AppCatalog
from kedro_boot.pipeline import DEFAULT_PIPELINE_VIEW_NAME, AppPipeline

LOGGER = logging.getLogger(__name__)


class KedroBootSession:
    """``KedroBootSession`` is the object that is responsible for managing kedro boot app lifecycle.
    At init time : It wrap catalog as ``AppCatalog``
    At compilation time : It compile the ``AppCatalog`` making it ready for iteration time.
    At iteration time: It render/merge ``AppCatalog`` with app data and run the ``AppPipeline``
    """

    def __init__(
        self,
        pipeline: AppPipeline,
        catalog: DataCatalog,
        hook_manager: PluginManager,
        session_id: str,
        config_loader: OmegaConfigLoader,
    ) -> None:
        """Init the kedro boot session.

        Args:
            pipeline (Pipeline): ``AppPipeline`` object
            catalog (DataCatalog): kedro ``DataCatalog`` object
            hook_manager (PluginManager): kedro  ``PluginManager`` object
            session_id (str): kedro ``KedroSession`` session_id
            config_loader (OmegaConfigLoader): kedro ``OmegaConfigLoader`` object
        """
        self._pipeline = pipeline
        self._catalog = AppCatalog(catalog)
        self._hook_manager = hook_manager
        self._session_id = session_id

        self._is_catalog_compiled = None

        self.config_loader = config_loader

    def compile_catalog(
        self,
    ) -> None:
        """Prepare ``AppCatalog`` for iteration time by creating catalog views using ``AppPipeline`` views.
        A pipeline view provides a perspective on the underlying pipeline, filtered by a particular tag and organized by datasets categories according to their relevance to the external application.
        The compilation is triggered automatically by the kedro boot. To give the app the control of the compilation point, start the project by ``kedro boot --lazy-compile``. If the compilation is neither triggered by the kedro project nor the app, it will be triggered lazily during the first run iteration.


        Raises:
            KedroBootSessionError: _description_
        """
        if self._is_catalog_compiled:
            raise KedroBootSessionError("The AppCatalog is already compiled")

        self._catalog.compile(self._pipeline)

        self._is_catalog_compiled = True

    def run(
        self,
        name: Optional[str] = None,
        inputs: Optional[dict] = None,
        parameters: Optional[dict] = None,
        template_params: Optional[dict] = None,
        run_id: Optional[str] = None,
    ) -> Any:
        """run the ``AppPipeline`` view using the provided inputs, parameters and templates.

        Args:
            name (str): name of the pipeline view.
            inputs (dict): App inputs datasets that will be injected into the catalog.
            parameters (dict): App parameters datasets that will be injected into the catalog.
            template_params (dict): App templates params that will render the template expressions.
            run_id (str): run_id can be generated by the app, otherwise the session generate it at each iteration.

        Raises:
            KedroBootSessionError: _description_

        Returns:
            Any: Run results
        """
        pipeline_view_name = name or DEFAULT_PIPELINE_VIEW_NAME
        iteration_run_id = run_id or uuid.uuid4().hex
        template_params = template_params or {}
        iteration_template_params = {**template_params, **{"run_id": iteration_run_id}}

        LOGGER.info(f"Running iteration {iteration_run_id}")
        # Coompile catalog lazily at first iteration, if it is not already compiled earlier by the app
        if not self._is_catalog_compiled:
            LOGGER.info("Lazy Catalog compilation at first iteration run ...")
            self.compile_catalog()

        pipeline_view = self._pipeline.get_view(pipeline_view_name)
        pipeline = self._pipeline.get_physical_pipeline(pipeline_view_name)
        catalog = self._catalog.render(
            name=pipeline_view_name,
            inputs=inputs,
            parameters=parameters,
            template_params=iteration_template_params,
        )

        # TODO: expose the choice of the runner to the user through app_pipeline
        runner = SequentialRunner()

        runner.run(
            pipeline=pipeline,
            catalog=catalog,
            hook_manager=self._hook_manager,
            session_id=self._session_id,
        )

        pipeline_outputs = pipeline.outputs()
        pipeline_view_outputs = set(pipeline_view.outputs)
        iteration_outputs = _get_iteration_outputs(
            catalog, pipeline_outputs, pipeline_view_outputs
        )  # type: ignore

        LOGGER.info(f"Iteration {iteration_run_id} completed")

        return iteration_outputs


def _get_iteration_outputs(
    catalog: DataCatalog, pipeline_outputs: Set[str], pipeline_view_outputs: Set[str]
) -> dict:
    """helper that load the run iteration outputs from the catalog.

    Args:
        catalog (DataCatalog): kedro catalog
        pipeline_outputs (set[str]): pipeline free outputs
        pipeline_view_outputs (set[str]): outputs exposed to the app

    Returns:
        dict: _description_
    """

    output_datasets = {}
    # if multiple outputs datasets, load the returned datasets indexed by pipeline view outputs
    if pipeline_view_outputs and len(pipeline_view_outputs) > 1:
        output_datasets = {
            dataset_name: catalog.load(dataset_name)
            for dataset_name in pipeline_view_outputs
        }
    elif pipeline_view_outputs and len(pipeline_view_outputs) == 1:
        output_datasets = catalog.load(list(pipeline_view_outputs)[0])
    # If no pipeline view outputs, load all the memorydatasets outputs
    else:
        output_datasets = {
            dataset_name: catalog.load(dataset_name)
            for dataset_name in pipeline_outputs
            if catalog._data_sets[dataset_name].__class__.__name__.lower()
            == "memorydataset"
        }
    return output_datasets


class KedroBootSessionError(Exception):
    """Error raised in case of kedro boot session error"""
